{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a114aa58-a22e-4d14-a13f-9db0d64c68d9",
   "metadata": {},
   "source": [
    "## 2024/11/15 - Trying out Basic Recommender Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c24f26d-16ac-4663-bc05-13b5862cd0d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7b75bcb3c690>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from enum import IntEnum\n",
    "from typing import Optional\n",
    "\n",
    "import fire\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import wandb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset import MovieLens20MDataset, RatingFormat, DatasetSource, CriteoDataset\n",
    "from metrics import ndcg_score, novelty_score, prediction_coverage_score, catalog_coverage_score, personalization_score\n",
    "from models import RecModel, ModelArchitecture, models_dict\n",
    "from utils import get_available_device\n",
    "\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d63c14d3-9c0d-4f0f-b70d-446b540694e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params:\n",
    "    learning_rate: int = 5e-3\n",
    "    weight_decay: float = 1e-5\n",
    "\n",
    "    embedding_dim: int = 32\n",
    "    dropout: float = 0.2\n",
    "    batch_size: int = 32\n",
    "    eval_size: int = 100\n",
    "    max_rows: int = 1000\n",
    "    model_architecture: ModelArchitecture = ModelArchitecture.MATRIX_FACTORIZATION\n",
    "    dataset_source: DatasetSource = DatasetSource.MOVIELENS\n",
    "    rating_format: RatingFormat = RatingFormat.RATING\n",
    "    max_users: Optional[int] = None\n",
    "    num_epochs: int = 100\n",
    "\n",
    "    do_eval: bool = True\n",
    "    eval_every: int = 5\n",
    "    max_batches: int = 10\n",
    "\n",
    "    @classmethod\n",
    "    def default_values(cls):\n",
    "        instance = cls()\n",
    "        attrs_dict = {\n",
    "            attr: getattr(instance, attr)\n",
    "            for attr in dir(instance)\n",
    "            if not callable(getattr(instance, attr)) and not attr.startswith(\"__\")\n",
    "        }\n",
    "        for key, value in attrs_dict.items():\n",
    "            if isinstance(value, IntEnum):\n",
    "                attrs_dict[key] = value.name\n",
    "        return attrs_dict\n",
    "\n",
    "\n",
    "class RecommenderModule(nn.Module):\n",
    "    def __init__(self, recommender: RecModel, use_wandb: bool):\n",
    "        super().__init__()\n",
    "        self.recommender = recommender\n",
    "        if (\n",
    "            Params.rating_format == RatingFormat.BINARY\n",
    "            and Params.model_architecture != ModelArchitecture.MATRIX_FACTORIZATION\n",
    "        ):\n",
    "            self.loss_fn = torch.nn.BCELoss()\n",
    "        else:\n",
    "            self.loss_fn = torch.nn.MSELoss()\n",
    "        self.use_wandb = use_wandb\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        _, ratings = batch\n",
    "        preds = self.recommender(batch).squeeze()\n",
    "        loss = self.loss_fn(preds, ratings)\n",
    "        # print(f\"Loss: {loss.item():03.3f} preds: {preds.tolist()} ratings: {ratings.tolist()}\")\n",
    "        if self.use_wandb:\n",
    "            wandb.log({\"train_loss\": loss})\n",
    "        return loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def eval_step(self, dataset: MovieLens20MDataset, batch, k: int = 10):\n",
    "        features, ratings = batch\n",
    "        users, items = features[:, 0], features[:, 1]\n",
    "        max_user_id = int(users.max().item() + 1)\n",
    "        preds = self.recommender(batch).squeeze()\n",
    "        eval_loss = self.loss_fn(preds, ratings).item()\n",
    "        user_item_ratings = np.empty((max_user_id, k))\n",
    "        true_item_ratings = np.empty((max_user_id, k))\n",
    "        for i, user_id in enumerate(users):\n",
    "            user_id = user_id.int().item()\n",
    "            # predict every item for every user\n",
    "            user_ids = torch.full_like(items, user_id)\n",
    "            user_batch = torch.stack([user_ids, items], dim=1)\n",
    "            user_preds = self.recommender((user_batch, None)).squeeze()\n",
    "            top_k_preds = torch.topk(user_preds, k=k).indices\n",
    "            user_item_ratings[user_id] = top_k_preds.cpu().numpy()\n",
    "\n",
    "            true_top_k = torch.topk(ratings, k=k).indices\n",
    "            true_item_ratings[user_id] = true_top_k.cpu().numpy()\n",
    "            if i == 0:\n",
    "                dataset.display_recommendation_output(user_id, top_k_preds.cpu().numpy(), true_top_k.cpu().numpy())\n",
    "\n",
    "            unique_item_catalog = list(set(items.tolist()))\n",
    "            item_popularity = defaultdict(int)\n",
    "            for item in items:\n",
    "                item_popularity[item.item()] += 1\n",
    "\n",
    "            num_users = len(list(set(users.tolist())))\n",
    "            num_items = len(list(set(items.tolist())))\n",
    "\n",
    "            novelty = novelty_score(user_item_ratings, item_popularity, num_users, num_items)\n",
    "\n",
    "            user_rating_preds = np.array([p for sublist in user_item_ratings for p in sublist])\n",
    "            user_rating_ref = np.array([p for sublist in user_item_ratings for p in sublist])\n",
    "\n",
    "            prediction_coverage = prediction_coverage_score(user_item_ratings, unique_item_catalog)\n",
    "            catalog_coverage = catalog_coverage_score(user_item_ratings, unique_item_catalog, k)\n",
    "\n",
    "            personalization = personalization_score(user_item_ratings)\n",
    "\n",
    "            ref_bool, preds_bool = user_rating_ref.astype(bool), user_rating_preds.astype(bool)\n",
    "            # Handle the case where all values are T or F\n",
    "            if len(np.unique(ref_bool)) == 2 and len(np.unique(preds_bool)) == 2:\n",
    "                roc_auc = roc_auc_score(ref_bool, preds_bool)\n",
    "\n",
    "            # gives the index of the top k predictions for each sample\n",
    "            log_dict = {\n",
    "                \"eval_loss\": eval_loss,\n",
    "                \"ndcg\": ndcg_score(user_rating_preds, user_rating_ref),\n",
    "                \"novelty\": novelty,\n",
    "                \"prediction_coverage\": prediction_coverage,\n",
    "                \"catalog_coverage\": catalog_coverage,\n",
    "                \"personalization\": personalization,\n",
    "                \"roc_auc\": roc_auc,\n",
    "            }\n",
    "            log_dict = {k: float(v) for k, v in log_dict.items()}\n",
    "\n",
    "            print(log_dict)\n",
    "            if self.use_wandb:\n",
    "                wandb.log(log_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1905e9cb-3f4d-4a80-a753-2005f2ed27b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset..\n",
      "Number of users: 4 | Number of movies: 187593 | Number of samples: 1000\n"
     ]
    }
   ],
   "source": [
    "use_wandb = False\n",
    "device = get_available_device()\n",
    "print(\"Loading dataset..\")\n",
    "dataset = MovieLens20MDataset(\"ml-25m\", Params.rating_format, Params.max_rows, Params.max_users)\n",
    "train_size = len(dataset) - Params.eval_size\n",
    "train_dataset, eval_dataset = torch.utils.data.random_split(dataset, [train_size, Params.eval_size])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=Params.batch_size, shuffle=True, num_workers=8)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=Params.eval_size, shuffle=True, num_workers=8)\n",
    "model_cls: RecModel = models_dict[Params.model_architecture]\n",
    "\n",
    "model: RecModel = model_cls(\n",
    "    dataset.emb_columns,\n",
    "    dataset.feature_sizes,\n",
    "    Params.embedding_dim,\n",
    "    Params.rating_format,\n",
    ").to(device)\n",
    "model.train()\n",
    "\n",
    "module = RecommenderModule(model, use_wandb).to(device)\n",
    "if use_wandb:\n",
    "    wandb.init(project=\"recsys\", config=Params.default_values())\n",
    "    wandb.watch(model)\n",
    "optimizer = AdamW(module.parameters(), lr=Params.learning_rate, weight_decay=Params.weight_decay)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=Params.num_epochs, eta_min=1e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c75cbed8-aa09-4ba0-a918-0f4a85892f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   2., 1376.]), np.float32(5.0))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d58a749-81a6-42ba-a20d-dcf3b102f3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1.0000e+00, 7.3270e+03],\n",
       "         [2.0000e+00, 7.3860e+03],\n",
       "         [2.0000e+00, 1.2710e+03],\n",
       "         [3.0000e+00, 7.4500e+02],\n",
       "         [3.0000e+00, 8.6880e+04],\n",
       "         [3.0000e+00, 5.7640e+04],\n",
       "         [3.0000e+00, 2.7134e+04],\n",
       "         [3.0000e+00, 1.1214e+05],\n",
       "         [1.0000e+00, 1.2370e+03],\n",
       "         [3.0000e+00, 9.8809e+04],\n",
       "         [2.0000e+00, 6.9470e+03],\n",
       "         [3.0000e+00, 4.2738e+04],\n",
       "         [3.0000e+00, 1.2740e+03],\n",
       "         [3.0000e+00, 6.1248e+04],\n",
       "         [3.0000e+00, 7.0286e+04],\n",
       "         [4.0000e+00, 2.9510e+03],\n",
       "         [3.0000e+00, 9.1658e+04],\n",
       "         [3.0000e+00, 2.7773e+04],\n",
       "         [4.0000e+00, 4.9630e+03],\n",
       "         [3.0000e+00, 5.6300e+03],\n",
       "         [3.0000e+00, 4.3880e+03],\n",
       "         [4.0000e+00, 1.2780e+03],\n",
       "         [2.0000e+00, 1.2010e+03],\n",
       "         [3.0000e+00, 6.5390e+03],\n",
       "         [3.0000e+00, 4.8660e+03],\n",
       "         [1.0000e+00, 1.6530e+03],\n",
       "         [3.0000e+00, 3.5780e+03],\n",
       "         [3.0000e+00, 3.1560e+03],\n",
       "         [3.0000e+00, 1.0000e+00],\n",
       "         [3.0000e+00, 5.5280e+03],\n",
       "         [4.0000e+00, 9.2400e+02],\n",
       "         [3.0000e+00, 9.4777e+04]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([3.5000, 4.0000, 1.5000, 5.0000, 4.0000, 4.0000, 4.5000, 3.0000, 5.0000,\n",
       "         4.0000, 4.0000, 4.0000, 4.5000, 2.5000, 4.0000, 3.5000, 4.0000, 5.0000,\n",
       "         4.5000, 3.0000, 3.0000, 4.0000, 2.5000, 4.0000, 4.0000, 4.0000, 4.5000,\n",
       "         4.5000, 4.0000, 3.5000, 4.0000, 3.5000], device='cuda:0')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # def forward(self, batch):\n",
    "    #     embeddings = self.get_feature_embeddings(batch, concat=False)\n",
    "    #     if len(embeddings.shape) == 2:\n",
    "    #         embeddings = embeddings.unsqueeze(0)\n",
    "    #     embeddings_prod = torch.prod(embeddings, dim=1)\n",
    "    #     interaction = torch.sum(embeddings_prod, dim=1)\n",
    "    #     return interaction\n",
    "\n",
    "\n",
    "batch = [x.to(device) for x in next(iter(train_dataloader))]\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb5c88ba-b19d-4d6f-9fcb-2cc07453a32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = model.get_feature_embeddings(batch, concat=True)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6405740-aecb-4a0c-b2b5-2d3185da826b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['userId', 'movieId']\n",
      "userId torch.Size([32]) - embed colum: torch.Size([32, 32])\n",
      "movieId torch.Size([32]) - embed colum: torch.Size([32, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5398, -0.2413,  1.4755,  ..., -0.3846, -0.8592, -0.1264],\n",
       "         [-0.8219,  0.9715,  1.9275,  ...,  0.3763,  0.2430,  0.7216]],\n",
       "\n",
       "        [[-0.2054, -1.2231, -0.4001,  ..., -0.6790,  0.5526,  1.2064],\n",
       "         [-1.6506,  1.3266, -0.4446,  ..., -0.5345,  0.1374, -0.3594]],\n",
       "\n",
       "        [[-0.2054, -1.2231, -0.4001,  ..., -0.6790,  0.5526,  1.2064],\n",
       "         [ 1.5995,  1.9885, -1.7979,  ...,  1.2579,  0.4153,  0.9821]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.1143, -1.2265,  0.2104,  ...,  1.2462, -1.0656,  0.6499],\n",
       "         [ 0.1838, -0.1535, -1.1579,  ...,  1.0284, -0.1032, -0.2692]],\n",
       "\n",
       "        [[ 0.8566,  0.3501,  0.1683,  ...,  0.2818,  0.4798,  1.9449],\n",
       "         [-1.0123, -0.8109, -0.0621,  ...,  0.3550,  0.4154,  1.0878]],\n",
       "\n",
       "        [[ 0.1143, -1.2265,  0.2104,  ...,  1.2462, -1.0656,  0.6499],\n",
       "         [-1.0835,  0.4426, -0.1829,  ..., -0.2556,  0.2262,  1.3089]]],\n",
       "       device='cuda:0', grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_feature_embeddings(self, batch, concat=True):\n",
    "    features, _ = batch\n",
    "    embeddings = []\n",
    "    print(self.emb_columns)\n",
    "    for i, feature_name in enumerate(self.emb_columns):\n",
    "        emb = self.emb_dict[feature_name]\n",
    "        feature_column = features[:, i].to(torch.int64)\n",
    "        embedded_column = emb(feature_column)\n",
    "        print(f'{feature_name} {feature_column.shape} - embed colum: {embedded_column.shape}')\n",
    "        embeddings.append(embedded_column)\n",
    "    embeddings = torch.stack(embeddings, dim=1).squeeze()\n",
    "    if concat:\n",
    "        embeddings = embeddings.view(-1, self.emb_in_size)\n",
    "    return embeddings\n",
    "\n",
    "get_feature_embeddings(model, batch, concat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be940140-bf4c-4e58-96b0-b7b3959525c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  7327,   7386,   1271,    745,  86880,  57640,  27134, 112138,   1237,\n",
       "         98809,   6947,  42738,   1274,  61248,  70286,   2951,  91658,  27773,\n",
       "          4963,   5630,   4388,   1278,   1201,   6539,   4866,   1653,   3578,\n",
       "          3156,      1,   5528,    924,  94777], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0][:, 1].to(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3dbe8492-6800-4784-8aa2-0cfd9b293bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b338bf6b-b6b7-453e-a684-28505ecbc0bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
